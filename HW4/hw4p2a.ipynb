{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0e1766cebf3df6a1c3bfac07f2a721876b9859be16ef7357b0b9094e11afc09f4",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff620cbbc30>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data-unversioned/p1ch6/cifar-10-python.tar.gz\n",
      "170499072it [00:32, 5291536.04it/s]                               \n",
      "Extracting ../data-unversioned/p1ch6/cifar-10-python.tar.gz to ../data-unversioned/p1ch6/\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torchvision import datasets, transforms\n",
    "data_path = '../data-unversioned/p1ch6/'\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))\n",
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {6: 0, 7: 1, 8: 2, 9: 3}\n",
    "class_names = ['frog', 'horse', 'ship', 'truck']\n",
    "cifar4 = [(img, label_map[label])\n",
    "          for img, label in cifar10 \n",
    "          if label in [6, 7, 8, 9]]\n",
    "cifar4_val = [(img, label_map[label])\n",
    "              for img, label in cifar10_val\n",
    "              if label in [6, 7, 8, 9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = out.view(-1, 8 * 8 * 8) # <1>\n",
    "        out = self.act3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device)  # <1>\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training on device cuda.\n",
      "2021-04-19 18:18:20.296050 Epoch 1, Training loss 1.1301657207095965\n",
      "2021-04-19 18:18:27.401526 Epoch 10, Training loss 0.5204326878911771\n",
      "2021-04-19 18:18:34.936812 Epoch 20, Training loss 0.35997181154858954\n",
      "2021-04-19 18:18:42.466178 Epoch 30, Training loss 0.29322803825044785\n",
      "2021-04-19 18:18:49.931627 Epoch 40, Training loss 0.24757534660660802\n",
      "2021-04-19 18:18:57.363323 Epoch 50, Training loss 0.21553016941958722\n",
      "2021-04-19 18:19:04.804121 Epoch 60, Training loss 0.18973186076544343\n",
      "2021-04-19 18:19:12.334651 Epoch 70, Training loss 0.16738538921307833\n",
      "2021-04-19 18:19:19.691568 Epoch 80, Training loss 0.1494107089770107\n",
      "2021-04-19 18:19:27.102634 Epoch 90, Training loss 0.13331729198654238\n",
      "2021-04-19 18:19:34.448802 Epoch 100, Training loss 0.1193500435449921\n",
      "2021-04-19 18:19:41.860092 Epoch 110, Training loss 0.10669211797511426\n",
      "2021-04-19 18:19:49.228394 Epoch 120, Training loss 0.09267599922351943\n",
      "2021-04-19 18:19:56.686352 Epoch 130, Training loss 0.08262956605111353\n",
      "2021-04-19 18:20:04.151895 Epoch 140, Training loss 0.07297309573751669\n",
      "2021-04-19 18:20:11.574095 Epoch 150, Training loss 0.06351685296958343\n",
      "2021-04-19 18:20:18.967775 Epoch 160, Training loss 0.05628970742356568\n",
      "2021-04-19 18:20:26.440231 Epoch 170, Training loss 0.04861712726517417\n",
      "2021-04-19 18:20:33.898450 Epoch 180, Training loss 0.042155417045370076\n",
      "2021-04-19 18:20:41.322189 Epoch 190, Training loss 0.037553656638001864\n",
      "2021-04-19 18:20:48.808187 Epoch 200, Training loss 0.032260194501152244\n",
      "149.27461075782776\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar4, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "model = Net().to(device=device)  # <1>\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "time1 = time.time()\n",
    "training_loop(\n",
    "    n_epochs = 200,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "time2 = time.time()\n",
    "time3 = time2-time1\n",
    "print(time3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy train: 0.99\nAccuracy val: 0.90\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar4, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar4_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "all_acc_dict = collections.OrderedDict()\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    accdict = {}\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device=device)\n",
    "                labels = labels.to(device=device)\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) # <1>\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "        accdict[name] = correct / total\n",
    "    return accdict\n",
    "\n",
    "all_acc_dict[\"baseline\"] = validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}