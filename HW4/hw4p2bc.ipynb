{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0e1766cebf3df6a1c3bfac07f2a721876b9859be16ef7357b0b9094e11afc09f4",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f90dd845c90>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "data_path = '../data-unversioned/p1ch6/'\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))\n",
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0:0,1:1,2:2,3:3,4:4,5:5,6:6,7:7,8:8,9:9}\n",
    "class_names = ['frog', 'horse', 'ship', 'truck']\n",
    "cifar10 = [(img, label_map[label])\n",
    "          for img, label in cifar10 \n",
    "          if label in [0,1,2,3,4,5,6,7,8,9]]\n",
    "cifar10_val = [(img, label_map[label])\n",
    "              for img, label in cifar10_val\n",
    "              if label in [0,1,2,3,4,5,6,7,8,9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = out.view(-1, 8 * 8 * 8) # <1>\n",
    "        out = self.act3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device)  # <1>\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training on device cuda.\n",
      "2021-04-19 18:28:28.818524 Epoch 1, Training loss 2.0283666259187565\n",
      "2021-04-19 18:28:45.587640 Epoch 10, Training loss 1.1541462195346424\n",
      "2021-04-19 18:29:04.678465 Epoch 20, Training loss 0.9853835153152876\n",
      "2021-04-19 18:29:21.895567 Epoch 30, Training loss 0.9043265613905914\n",
      "2021-04-19 18:29:38.874878 Epoch 40, Training loss 0.8506361666847678\n",
      "2021-04-19 18:29:55.848334 Epoch 50, Training loss 0.8108874876861987\n",
      "2021-04-19 18:30:12.802686 Epoch 60, Training loss 0.7797686700778239\n",
      "2021-04-19 18:30:30.027643 Epoch 70, Training loss 0.7529088753035001\n",
      "2021-04-19 18:30:47.533918 Epoch 80, Training loss 0.7283835992255174\n",
      "2021-04-19 18:31:05.228863 Epoch 90, Training loss 0.7111593760416636\n",
      "2021-04-19 18:31:21.033840 Epoch 100, Training loss 0.6899750372942757\n",
      "2021-04-19 18:31:36.732780 Epoch 110, Training loss 0.6753588111885368\n",
      "2021-04-19 18:31:52.364567 Epoch 120, Training loss 0.659693493448255\n",
      "2021-04-19 18:32:08.048809 Epoch 130, Training loss 0.6463711944306293\n",
      "2021-04-19 18:32:23.713469 Epoch 140, Training loss 0.6326680091945717\n",
      "2021-04-19 18:32:39.414953 Epoch 150, Training loss 0.6219999834780803\n",
      "2021-04-19 18:32:55.091182 Epoch 160, Training loss 0.6124722955324461\n",
      "2021-04-19 18:33:10.792704 Epoch 170, Training loss 0.6026692007432508\n",
      "2021-04-19 18:33:26.545512 Epoch 180, Training loss 0.5918361131492478\n",
      "2021-04-19 18:33:42.282833 Epoch 190, Training loss 0.5835013650262447\n",
      "2021-04-19 18:33:57.987395 Epoch 200, Training loss 0.576361718099288\n",
      "331.159099817276\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "model = Net().to(device=device)  # <1>\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "time1 = time.time()\n",
    "training_loop(\n",
    "    n_epochs = 200,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "time2 = time.time()\n",
    "time3 = time2-time1\n",
    "print(time3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy train: 0.80\nAccuracy val: 0.64\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "all_acc_dict = collections.OrderedDict()\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    accdict = {}\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device=device)\n",
    "                labels = labels.to(device=device)\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) # <1>\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "        accdict[name] = correct / total\n",
    "    return accdict\n",
    "\n",
    "all_acc_dict[\"baseline\"] = validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.conv3 = nn.Conv2d(8, 4, kernel_size=3, padding=1)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = out.view(-1, 8 * 8 * 8) # <1>\n",
    "        out = self.act3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training on device cuda.\n",
      "2021-04-19 18:47:45.419132 Epoch 1, Training loss 2.0419638056279448\n",
      "2021-04-19 18:48:01.846729 Epoch 10, Training loss 1.199456960572611\n",
      "2021-04-19 18:48:19.035296 Epoch 20, Training loss 1.0007705829866098\n",
      "2021-04-19 18:48:36.256423 Epoch 30, Training loss 0.9075732327940519\n",
      "2021-04-19 18:48:53.689035 Epoch 40, Training loss 0.8528787364892643\n",
      "2021-04-19 18:49:11.292671 Epoch 50, Training loss 0.8126222433336555\n",
      "2021-04-19 18:49:28.624747 Epoch 60, Training loss 0.7793253608753005\n",
      "2021-04-19 18:49:46.010818 Epoch 70, Training loss 0.751642483960637\n",
      "2021-04-19 18:50:03.337904 Epoch 80, Training loss 0.7293657463453614\n",
      "2021-04-19 18:50:19.779007 Epoch 90, Training loss 0.7085475045091966\n",
      "2021-04-19 18:50:35.646689 Epoch 100, Training loss 0.6903051066276668\n",
      "2021-04-19 18:50:51.871712 Epoch 110, Training loss 0.6735876949546892\n",
      "2021-04-19 18:51:07.774049 Epoch 120, Training loss 0.6610975086384112\n",
      "2021-04-19 18:51:23.877664 Epoch 130, Training loss 0.6466618820148355\n",
      "2021-04-19 18:51:39.930619 Epoch 140, Training loss 0.6336951764190898\n",
      "2021-04-19 18:51:56.121333 Epoch 150, Training loss 0.6248065530110503\n",
      "2021-04-19 18:52:11.955763 Epoch 160, Training loss 0.6132931851060189\n",
      "2021-04-19 18:52:29.072795 Epoch 170, Training loss 0.6045097138951806\n",
      "2021-04-19 18:52:46.153027 Epoch 180, Training loss 0.5949562088684048\n",
      "2021-04-19 18:53:03.235205 Epoch 190, Training loss 0.587537970041375\n",
      "2021-04-19 18:53:20.266817 Epoch 200, Training loss 0.5795372254632013\n",
      "336.59915018081665\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "model = Net().to(device=device)  # <1>\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "time1 = time.time()\n",
    "training_loop(\n",
    "    n_epochs = 200,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "time2 = time.time()\n",
    "time3 = time2-time1\n",
    "print(time3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy train: 0.79\nAccuracy val: 0.63\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "all_acc_dict = collections.OrderedDict()\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    accdict = {}\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device=device)\n",
    "                labels = labels.to(device=device)\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) # <1>\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "        accdict[name] = correct / total\n",
    "    return accdict\n",
    "\n",
    "all_acc_dict[\"baseline\"] = validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}