{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0e1766cebf3df6a1c3bfac07f2a721876b9859be16ef7357b0b9094e11afc09f4",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f72f82f4cb0>"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "data_path = '../data-unversioned/p1ch6/'\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))\n",
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0:0,1:1,2:2,3:3,4:4,5:5,6:6,7:7,8:8,9:9}\n",
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']\n",
    "cifar10 = [(img, label_map[label])\n",
    "          for img, label in cifar10 \n",
    "          if label in [0,1,2,3,4,5,6,7,8,9]]\n",
    "cifar10_val = [(img, label_map[label])\n",
    "              for img, label in cifar10_val\n",
    "              if label in [0,1,2,3,4,5,6,7,8,9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = out.view(-1, 8 * 8 * 8) # <1>\n",
    "        out = self.act3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device)  # <1>\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training on device cuda.\n",
      "2021-04-19 21:27:42.227406 Epoch 1, Training loss 2.028366512197363\n",
      "2021-04-19 21:28:01.843502 Epoch 10, Training loss 1.154138752947683\n",
      "2021-04-19 21:28:22.519436 Epoch 20, Training loss 0.9853798715049958\n",
      "2021-04-19 21:28:43.255942 Epoch 30, Training loss 0.9043115894965199\n",
      "2021-04-19 21:29:03.804381 Epoch 40, Training loss 0.850585126282309\n",
      "2021-04-19 21:29:24.046540 Epoch 50, Training loss 0.8108680477685026\n",
      "2021-04-19 21:29:44.406119 Epoch 60, Training loss 0.7796842048463919\n",
      "2021-04-19 21:30:05.670228 Epoch 70, Training loss 0.7528639595069544\n",
      "2021-04-19 21:30:29.450660 Epoch 80, Training loss 0.7283742182013934\n",
      "2021-04-19 21:30:52.698926 Epoch 90, Training loss 0.7110933865732549\n",
      "2021-04-19 21:31:15.200056 Epoch 100, Training loss 0.689933990159303\n",
      "2021-04-19 21:31:37.887068 Epoch 110, Training loss 0.6752988641600475\n",
      "2021-04-19 21:32:01.119611 Epoch 120, Training loss 0.6596245721859091\n",
      "2021-04-19 21:32:22.227179 Epoch 130, Training loss 0.6461609196098869\n",
      "2021-04-19 21:32:43.059029 Epoch 140, Training loss 0.6324292334449261\n",
      "2021-04-19 21:33:03.465249 Epoch 150, Training loss 0.6219678941132772\n",
      "2021-04-19 21:33:23.630292 Epoch 160, Training loss 0.6121794033385909\n",
      "2021-04-19 21:33:44.628935 Epoch 170, Training loss 0.6024170085368559\n",
      "2021-04-19 21:34:04.969854 Epoch 180, Training loss 0.5913849546171516\n",
      "2021-04-19 21:34:24.604142 Epoch 190, Training loss 0.5832531926272165\n",
      "2021-04-19 21:34:45.159113 Epoch 200, Training loss 0.5759490509434124\n",
      "427.16254925727844\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "model = Net().to(device=device)  # <1>\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "time1 = time.time()\n",
    "training_loop(\n",
    "    n_epochs = 200,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "time2 = time.time()\n",
    "time3 = time2-time1\n",
    "print(time3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy train: 0.75\nAccuracy val: 0.62\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "all_acc_dict = collections.OrderedDict()\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    accdict = {}\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device=device)\n",
    "                labels = labels.to(device=device)\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) # <1>\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "        accdict[name] = correct / total\n",
    "    return accdict\n",
    "\n",
    "all_acc_dict[\"baseline\"] = validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.conv3 = nn.Conv2d(8, 4, kernel_size=3, padding=1)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = out.view(-1, 8 * 8 * 8) # <1>\n",
    "        out = self.act3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training on device cuda.\n",
      "2021-04-19 21:47:39.648283 Epoch 1, Training loss 2.0409646256805383\n",
      "2021-04-19 21:47:54.789939 Epoch 10, Training loss 1.2012045902516835\n",
      "2021-04-19 21:48:11.485192 Epoch 20, Training loss 1.0187745111830093\n",
      "2021-04-19 21:48:28.284106 Epoch 30, Training loss 0.9258129337559575\n",
      "2021-04-19 21:48:45.047059 Epoch 40, Training loss 0.8698664039678281\n",
      "2021-04-19 21:49:01.861198 Epoch 50, Training loss 0.824110525724528\n",
      "2021-04-19 21:49:18.620275 Epoch 60, Training loss 0.7890334278345108\n",
      "2021-04-19 21:49:35.446955 Epoch 70, Training loss 0.7610324769449965\n",
      "2021-04-19 21:49:52.305443 Epoch 80, Training loss 0.7380371911598899\n",
      "2021-04-19 21:50:09.107795 Epoch 90, Training loss 0.7156534763934362\n",
      "2021-04-19 21:50:25.861680 Epoch 100, Training loss 0.6969152129519626\n",
      "2021-04-19 21:50:42.539987 Epoch 110, Training loss 0.6814602776180447\n",
      "2021-04-19 21:50:59.327060 Epoch 120, Training loss 0.6656537890967811\n",
      "2021-04-19 21:51:16.088758 Epoch 130, Training loss 0.6503787103973692\n",
      "2021-04-19 21:51:32.746966 Epoch 140, Training loss 0.638252564289076\n",
      "2021-04-19 21:51:49.402057 Epoch 150, Training loss 0.6272102953375452\n",
      "2021-04-19 21:52:06.144279 Epoch 160, Training loss 0.6175356442513673\n",
      "2021-04-19 21:52:24.743913 Epoch 170, Training loss 0.6082561753518746\n",
      "2021-04-19 21:52:43.474911 Epoch 180, Training loss 0.5977605398353714\n",
      "2021-04-19 21:53:01.815773 Epoch 190, Training loss 0.5902983362564955\n",
      "2021-04-19 21:53:20.634747 Epoch 200, Training loss 0.5817880297408384\n",
      "342.67397832870483\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "model = Net().to(device=device)  # <1>\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "time1 = time.time()\n",
    "training_loop(\n",
    "    n_epochs = 200,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "time2 = time.time()\n",
    "time3 = time2-time1\n",
    "print(time3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy train: 0.79\nAccuracy val: 0.64\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "all_acc_dict = collections.OrderedDict()\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    accdict = {}\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device=device)\n",
    "                labels = labels.to(device=device)\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) # <1>\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "        accdict[name] = correct / total\n",
    "    return accdict\n",
    "\n",
    "all_acc_dict[\"baseline\"] = validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}