{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0e1766cebf3df6a1c3bfac07f2a721876b9859be16ef7357b0b9094e11afc09f4",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2abe39ddf0>"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "data_path = '../data-unversioned/p1ch6/'\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))\n",
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0:0,1:1,2:2,3:3,4:4,5:5,6:6,7:7,8:8,9:9}\n",
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']\n",
    "cifar10 = [(img, label_map[label])\n",
    "          for img, label in cifar10 \n",
    "          if label in [0,1,2,3,4,5,6,7,8,9]]\n",
    "cifar10_val = [(img, label_map[label])\n",
    "              for img, label in cifar10_val\n",
    "              if label in [0,1,2,3,4,5,6,7,8,9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training on device cuda.\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")\n",
    "import datetime  # <1>\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device)  # <1>\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-04-22 10:44:59.129053 Epoch 1, Training loss 2.0323531330394013\n",
      "2021-04-22 10:45:15.669233 Epoch 10, Training loss 1.2034821423423259\n",
      "2021-04-22 10:45:34.179422 Epoch 20, Training loss 1.0340060676302751\n",
      "2021-04-22 10:45:52.051089 Epoch 30, Training loss 0.9422119404653759\n",
      "2021-04-22 10:46:09.803114 Epoch 40, Training loss 0.8898053870481604\n",
      "2021-04-22 10:46:26.460008 Epoch 50, Training loss 0.8442033366931369\n",
      "2021-04-22 10:46:41.662469 Epoch 60, Training loss 0.8061694959392938\n",
      "2021-04-22 10:46:57.702884 Epoch 70, Training loss 0.7721621378913255\n",
      "2021-04-22 10:47:14.467652 Epoch 80, Training loss 0.7460503187935675\n",
      "2021-04-22 10:47:30.691503 Epoch 90, Training loss 0.7216090995180028\n",
      "2021-04-22 10:47:46.874608 Epoch 100, Training loss 0.701349069928879\n",
      "2021-04-22 10:48:03.295068 Epoch 110, Training loss 0.684777773592783\n",
      "2021-04-22 10:48:20.537671 Epoch 120, Training loss 0.668162872724216\n",
      "2021-04-22 10:48:37.910204 Epoch 130, Training loss 0.6535478259062828\n",
      "2021-04-22 10:48:55.367597 Epoch 140, Training loss 0.6416633351303428\n",
      "2021-04-22 10:49:12.973276 Epoch 150, Training loss 0.6299853934656323\n",
      "2021-04-22 10:49:30.400166 Epoch 160, Training loss 0.619773290575008\n",
      "2021-04-22 10:49:47.303310 Epoch 170, Training loss 0.6103356945545168\n",
      "2021-04-22 10:50:03.974951 Epoch 180, Training loss 0.6012078835759931\n",
      "2021-04-22 10:50:20.756879 Epoch 190, Training loss 0.5930960940582978\n",
      "2021-04-22 10:50:37.716393 Epoch 200, Training loss 0.587040222819199\n",
      "340.2452220916748\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "model = Net().to(device=device)  # <1>\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "time1 = time.time()\n",
    "training_loop(\n",
    "    n_epochs = 200,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "time2 = time.time()\n",
    "time3 = time2-time1\n",
    "print(time3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy train: 0.77\nAccuracy val: 0.63\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "all_acc_dict = collections.OrderedDict()\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    accdict = {}\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device=device)\n",
    "                labels = labels.to(device=device)\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) # <1>\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "        accdict[name] = correct / total\n",
    "    return accdict\n",
    "\n",
    "all_acc_dict[\"baseline\"] = validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetDepth(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3,\n",
    "                               padding=1)\n",
    "        self.conv3 = nn.Conv2d(n_chans1 // 2, n_chans1 // 2,\n",
    "                               kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv3(out)), 2)\n",
    "        out = out.view(-1, 4 * 4 * self.n_chans1 // 2)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-04-22 11:02:30.493220 Epoch 1, Training loss 2.139684502426011\n",
      "2021-04-22 11:02:49.264088 Epoch 10, Training loss 1.1827155721309546\n",
      "2021-04-22 11:03:11.092876 Epoch 20, Training loss 0.9419638391041085\n",
      "2021-04-22 11:03:34.721736 Epoch 30, Training loss 0.8284895798891706\n",
      "2021-04-22 11:03:57.895880 Epoch 40, Training loss 0.7629766038159276\n",
      "2021-04-22 11:04:20.864160 Epoch 50, Training loss 0.7176013890358494\n",
      "2021-04-22 11:04:43.940289 Epoch 60, Training loss 0.6831804167126756\n",
      "2021-04-22 11:05:06.986145 Epoch 70, Training loss 0.6547993553416503\n",
      "2021-04-22 11:05:29.956238 Epoch 80, Training loss 0.6310977951797379\n",
      "2021-04-22 11:05:52.906152 Epoch 90, Training loss 0.6103006697752896\n",
      "2021-04-22 11:06:15.948479 Epoch 100, Training loss 0.5921452348418248\n",
      "2021-04-22 11:06:38.931190 Epoch 110, Training loss 0.5756092067341061\n",
      "2021-04-22 11:07:01.883001 Epoch 120, Training loss 0.5606479425259563\n",
      "2021-04-22 11:07:24.829865 Epoch 130, Training loss 0.546694454139151\n",
      "2021-04-22 11:07:47.913774 Epoch 140, Training loss 0.5339078013511265\n",
      "2021-04-22 11:08:10.865561 Epoch 150, Training loss 0.5217112872339881\n",
      "2021-04-22 11:08:33.784068 Epoch 160, Training loss 0.5103990573369329\n",
      "2021-04-22 11:08:56.726996 Epoch 170, Training loss 0.5003186650097827\n",
      "2021-04-22 11:09:19.755231 Epoch 180, Training loss 0.49061706988021847\n",
      "2021-04-22 11:09:42.713018 Epoch 190, Training loss 0.48153652245050194\n",
      "2021-04-22 11:10:05.684286 Epoch 200, Training loss 0.47336443328796446\n",
      "Accuracy train: 0.82\n",
      "Accuracy val: 0.68\n",
      "459.05471181869507\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = NetDepth(n_chans1=32).to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "time1 = time.time()\n",
    "training_loop(\n",
    "    n_epochs = 200,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "all_acc_dict[\"depth\"] = validate(model, train_loader, val_loader)\n",
    "time2 = time.time()\n",
    "time3 = time2-time1\n",
    "print(time3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy train: 0.82\nAccuracy val: 0.68\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "all_acc_dict = collections.OrderedDict()\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    accdict = {}\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device=device)\n",
    "                labels = labels.to(device=device)\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) # <1>\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "        accdict[name] = correct / total\n",
    "    return accdict\n",
    "\n",
    "all_acc_dict[\"baseline\"] = validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finish"
   ]
  }
 ]
}